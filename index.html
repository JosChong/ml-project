<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta charset="utf-8">
    <title>Machine Learning & Video Games</title>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Nunito+Sans">
    <link rel="stylesheet" href="css/master.css">
  </head>
  <body>

    <div class="col-md-5 col-md-offset-1 text-right header">
      <u><h1>MACHINE LEARNING & VIDEO GAMES:</h1></u>
      <h2>Using Mouse Movement to Predict Game Genre</h2>
      <h3>Yoonsang Chong</h3>
      <h4>yoonsangchong2016@u.northwestern.edu</h4>
      <h4>Northwestern University EECS 349</h4>
    </div>

    <div class="col-md-8 col-md-offset-3 intro">
      <p><div class="tab">C</div>an a machine tell what type of game a person is playing, just given a visual representation of their in-game mouse movements? If so, it could signify a new avenue for gaming mouse software developers to explore, where a mouse can interact with a gamer with the same personalization and usefulness as other types of modern “smart” technology. An obvious initial usage would be for a mouse to automatically adjust its sensitivity as its user switches between different games, or between gaming and not gaming. This would enable seamless transitions between activities, and take the manual work off of users’ hands. But the possibilities go much beyond that; using movements to analyze play style, we might be able to recommend games of similar "activeness," pinpoint specific areas for players to improve upon their skills, or offer developers a tool to help them design gameplay mechanics and systems that reach their target audience.</p>
    </div>

    <div class="col-md-12 black">
      <div class="col-md-5 col-md-offset-1">
        <p><div class="tab"></div>The first step in approaching this task lays in which machine learning algorithm to use. Luckily, in the case of image classification, there is a popular option and for good reason: convolutional neural nets have been proven to be quite effective at recognizing patterns in images, even if the images at first may seem very dissimilar in terms of their underlying machine representation. The idea is to translate the images into arrays of values, then feed them into a convolutional neural network designed to learn how to predict the images' labels.</p>
        <p><div class="tab"></div>In some ways, the resulting trained model turned out to be more effective than expected. When training on the three main genres of games on which data was collected (FPS, RTS, and card games), the network was capable of achieving near 100% accuracy in the task of distinguishing a particular genre from others with only several tens of examples. With some tuning of parameters, a near instant perfect accuracy can be achieved. However, a weakness of the model, or perhaps an oversight concerning the task in general, arose when comparing other portions of the collected data. Certain genres, although strikingly different in gameplay, share almost identical patterns of movement, and the limited scope of the data prevented a further investigation into whether or not they could be classified effectively by a CNN.</p>
      </div>
      <div class="col-md-4 col-md-offset-1 text-center">
        <img class="example-img" src="images/example.png">
        <p class="caption">One of the examples that shows the result of tracking mouse movements in the real-time strategy game, StarCraft II.</p>
      </div>
    </div>

    <div class="col-md-10 col-md-offset-1">
      <img class="pad" src="images/mousepad-title.png">
      <div class="col-md-5 col-md-offset-1">
        <p class="analysis">In Depth<br>Analysis</p>
      </div>
    </div>

    <div class="col-md-12 black">
      <div class="col-md-5 col-md-offset-1 text-center">
        <p class="section-title">DATASET</p>
        <p class="section-subtitle">GENERATION AND PREPROCESSING</p>
      </div>
      <div class="col-md-5">
        <p><div class="tab"></div>The dataset is comprised of just under 500 examples, with around 400 of them belonging to one of the 3 main genres between which the model showed high classification success: first-person shooter (FPS), real-time strategy (RTS), and card games. Although the original plan was to gather data on a wider range of genres, two issues arose that prevented that. First, the time cost of generating the data, even with several people assisting, proved to be a restricting factor when it came to how much experimentation could be done. But, at the same time, early observations revealed a possibility that was later corroborated by the gathered data: <i>genre differences are not all necessarily captured by mouse movement patterns</i>.</p>
      </div>
      <div class="col-md-5">
        <p><div class="tab"></div>As can be seen in the example data points below, some genres, although they might seem very distinct to the players (see RTS & MOBA), are seemingly indistinguishable when only given their tracking data. This seemed like a feasible possibility, so rather than to spend valuable resources on potentially trivial pursuits, future data generation was focused on the genres with which the model showed promise in preliminary testing, in order to explore the network's full capabilities. These genres each have unique characteristics in their movement patterns, clear to the human eye, which can act as sources of predictive significance when training a neural network.</p>
      </div>
    </div>

    <div class="col-md-12 text-center inner-pad">
      <div class="col-md-4">
        <img class="img" src="images/card.png">
        <p class="dark-caption">Hearthstone – Card Game</p>
      </div>
      <div class="col-md-4">
        <img class="img" src="images/fps.png">
        <p class="dark-caption">Overwatch – First-Person Shooter (FPS)</p>
      </div>
      <div class="col-md-4">
        <img class="img" src="images/moba.png">
        <p class="dark-caption">League of Legends – Massive Online Battle Arena (MOBA)</p>
      </div>
      <div class="col-md-4 col-md-offset-2">
        <img class="img" src="images/rpg.png">
        <p class="dark-caption">Diablo III – Top-Down Hack'n'Slash Role Playing Game (RPG)</p>
      </div>
      <div class="col-md-4">
        <img class="img" src="images/rts.png">
        <p class="dark-caption">StarCraft II – Real-Time Strategy (RTS)</p>
      </div>
    </div>

    <div class="col-md-12 black">
      <div class="col-md-5 col-md-offset-1">
        <p><div class="tab"></div>The data was split into training, validation, and testing sets with a standard ratio of 80/20/20. Due to the small nature of the dataset, it is important to maximize the size of the training set so as to give the model as much information as possible to learn from. On the other hand, if the validation or testing sets are too small, it becomes difficult to track and assess the growth of the model. So, a standard ratio was employed to maintain a balance between the two.</p>
        <p><div class="tab"></div>Initially, the data was going to be used in its native 2560x1440 resolution form, however, the extreme memory costs quickly made that an unviable choice. So, the images, once loaded into tensorflow, were reshaped to a 10x magnitude smaller size of 256x144 – although really the data was actually stored in 3-dimensional arrays, with each pixel in a 246x144 space being represented by an array of length 3 that specifies the RGB values. This manipulation of the images enabled them to be used to train models with reasonable memory and time requirements, and given the accuracies of the predictive results, it likely did not have any significant trade off in terms of loss of potential information gain.</p>
        <p><div class="tab"></div>The data was also all converted into B&W (as seen on the right) to check whether IOGraph’s (the program used to track the mouse movements) color scheme was influencing the capabilities of the model in any way. The findings seem to suggest that the impact is negligible. As when using the colored versions of the input images, it only took around 30 iterations of single-step single-example descent training for the model to achieve a 100% accuracy on the validation set.</p>
      </div>
      <div class="col-md-4 col-md-offset-1 text-center">
        <img class="example-img plus" src="images/example-bw.png">
        <p class="caption">An example of using thresholding to create a completely black & white variant of an image.</p>
      </div>
    </div>

    <div class="col-md-12 inner-pad">
      <div class="col-md-5 col-md-offset-1 text-center">
        <p class="section-title">METHODS</p>
        <p class="section-subtitle"></p>
      </div>
      <div class="col-md-5">
        <p><div class="tab"></div>There was only one type of machine learning algorithm used, and that was a convolutional neural network written in Python using tensorflow. Because the model had to be created and tuned manually through code, it was a fairly time consuming process. However, there were plenty of parameters to manipulate given this approach, which left a fair amount of room for experimentation within this specific model. The results and analyses of this “learning process design" are detailed below.</p>
        <p><div class="tab"></div>Also, one could presume that using a convolutional neural network to classify images of fixed sizes and fixed absolute anchors to which all movements are relative (the center of the screen) is unnecessary, as the strength of CNNs lay in their ability to detect patterns in different sections of images. But, the use of multilayer deep networks have more perks than simply being able to account for translation. The process of convolution and pooling means that small differences can be generalized to the same patterns, which is a useful feature for input data as volatile as mouse movement, where the exact angles at which the lines are made is anything but calculative and significant.</p>
      </div>
    </div>

    <div class="col-md-12 black">
      <div class="col-md-12">
        <div class="col-md-4 col-md-offset-4 text-center">
          <p class="section-title">RESULTS</p>
          <p class="section-subtitle">ANALYSIS & REFLECTION</p>
        </div>
      </div>

      <div class="col-md-12">
        <div class="col-md-5 col-md-offset-1">
          <p><div class="tab"></div>Originally, the biggest concern with regards to this task was potentially not having a large enough dataset to train an effective model. However, as noted, this was hardly the case. Using a convolutional neural network with 3 convolution layers, 3 pooling layers, and 2 fully connected layers between the inputs and output layer (not counting dropout and flattening layers), and utilizing batch gradient descent with a batch size of 10 examples and a step size also of 10 (the number of forward and backprop driven gradient update cycles per batch) over 50 iterations, the model can achieve over 95% validation accuracy off usually just a single batch. These fairly straightforward parameters for the model given the size and nature of the data seem to enable quick learning behavior, even with just a small number of examples.</p>
        </div>
        <div class="col-md-5">
          <p><div class="tab"></div>The stark differences between the mouse patterns of the focused genres are more effectively perceived and utilized by the algorithm than predicted, and this can be seen in the following graphs, which depict the growth of the model when training with various parameter configurations. Although using multiple example and multiple-step batch gradient descent trains the model more efficiently, the growth of the network's capabilities can be better observed when restricting the rate at which it can learn by using single-step descent on single example batches, which then allows one to better gauge the impact of changing other parameters. Even with this limitation, the network can still achieve 100% accuracy in the relatively short amount of time of about 30 to 40 iterations. The graphs are followed by a breakdown of some of the model's tunable parameters and their impact on the accuracy of the final result.</p>
        </div>
      </div>

      <div class="col-md-10 col-md-offset-1 minus">
        <div class="col-md-4 text-center">
          <img src="images/acc0.jpg">
        </div>
        <div class="col-md-4 text-center">
          <img src="images/acc1.jpg">
        </div>
        <div class="col-md-4 text-center">
          <img src="images/acc2.jpg">
        </div>
      </div>

      <div class="col-md-10 col-md-offset-1 minus">
        <div class="col-md-3 text-center">
          <h1>Batch Size</h1>
          <p>This parameter indicates the number of training examples used in each round of batch gradient descent. Ideally, a larger batch is better, as the "noise" of singular data examples can lead to erroneous learning. However, too large a batch size can also hurt accuracy, as the learning may not be well generalized. A batch size of 10, smaller than the standard sizes of 32 or 64, proved to be a workable size to calculate accurate gradients and train an effective model in this case, although its impact on anything outside of convergence speed is difficult to discern.</p>
        </div>
        <div class="col-md-3 text-center">
          <h1>Iterations & Steps</h1>
          <p>These parameters are tied with batch size and each other. While the number of iterations determines how many batches will be used to train, the step chooses how many times the gradient of each batch is run through the network, like a learning rate for batches or batch gradients. However, for this task, these values are not too significant as the model does not require a lot of data to achieve high predictive success anyway. Using a step size of 1 instead of 10, for example, increases the number of batches required to achieve 100% validation accuracy, but doesn't affect the accuracy of the calculated gradients. So, unlike using a batch size of 1, it doesn't seem to affect the precision of the learning process so much as the efficiency. The number of iterations is set to 50, so that with a batch size of 10, the entirety of the data is used when training the network.</p>
        </div>
        <div class="col-md-3 text-center">
          <h1>Learning Rate</h1>
          <p>The learning rate indicates how much significance the model assigns to the calculated batch gradients when using them to adjust its internal weights. The value of this parameter has a large effect on the model's success, as too high a value causes the network to attribute too much importance to new training examples, making it volatile and susceptible to outlier examples, while too low a value leaves the model unable to effectively learn from the data at all. The following table shows how many iterations of single example single-step optimization iterations are required to achieve 100% accuracy given a specific learning rate:</p>
          <table align="center">
            <tr>
              <th>LR</th>
              <th># Iters</th>
            </tr>
            <tr>
              <td>1e-1</td>
              <td>–</td>
            </tr>
            <tr>
              <td>1e-2</td>
              <td>28</td>
            </tr>
            <tr>
              <td>1e-3</td>
              <td>15</td>
            </tr>
            <tr>
              <td>1e-4</td>
              <td>28</td>
            </tr>
            <tr>
              <td>1e-5</td>
              <td>17</td>
            </tr>
            <tr>
              <td>1e-6</td>
              <td>46</td>
            </tr>
            <tr>
              <td>1e-7</td>
              <td>–</td>
            </tr>
          </table>
        </div>
        <div class="col-md-3 text-center">
          <h1>Layers</h1>
          <p>Some experimentation was done in considering how many of which types of layers to use in the neural network. The following table shows the results of each variation:</p>
          <table align="center">
            <tr>
              <th>Variation</th>
              <th># Iters</th>
            </tr>
            <tr>
              <th>1C, 1P, 1FC&nbsp;&nbsp;</th>
              <th>14</th>
            </tr>
            <tr>
              <th>2C, 2P, 1FC</th>
              <th>25</th>
            </tr>
            <tr>
              <th>2C, 2P, 2FC</th>
              <th>15</th>
            </tr>
            <tr>
              <th>3C, 3P, 1FC</th>
              <th>16</th>
            </tr>
            <tr>
              <th>3C, 3P, 2FC</th>
              <th>13</th>
            </tr>
          </table>
          <p class="caption">Key<br>C: Convolution Layer<br>P: Pooling Layer<br>FC: Fully Connected Layer</p>
        </div>
      </div>
    </div>

  </body>
</html>
